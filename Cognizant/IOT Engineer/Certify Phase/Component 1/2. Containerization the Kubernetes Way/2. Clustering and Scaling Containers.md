Prerequisites for creating a Kubernetes cluster in EKS

- Before creating an Amazon EKS cluster we must create IAM role that Kubernetes can assume to create AWS resources

- For example, when load balancer is created, kubernetes assumes the role to create an ELB load balancer in your account

- Needs to be done only once and it can be used for multiple EKS cluster

- Also need to create a VPC and a security group for the cluster to use

- Although the VPC and security groups can be used for multiple EKS clusters, AWS recommends to use a separate VPC for each EKS cluster to provide better network isolation

STEPS for creating an IAM role:

1. Open [IAM Console](console.aws.amazon.com/iam)

2. Choose Roles and create roles

3. Choose EKS from the list of services

4. Allow Amazon EKS to manage your clusters on your behalf, then next -> Permissions

5. Next-> Review

6. For role name, Enter a unique name for the role then choose Create role

STEPS for creating a VPC:

1. Open [AWS CloudFormation](console.aws.amazon.com/cloudformation)

2. Select the region from the navigation bar that supports AWS EKS

3. Choose create Stack

4. Specify an Amazon S3 template URL for the template

5. Paste the following URL in text area and choose next:???
   https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-11-07/amazon-eks-vpc-sample.yaml

6. Fill the parameters accordingly on the Specify details page and choose Next

7. Choose a stack name for the AWS cloudFormation

8. VpcBlock - Choose a CIDR range for VPC (default)

9. Subnet01Block - Choose a CIDR range for VPC (default)

10. Subnet02Block - Choose a CIDR range for VPC (default)9. Subnet01Block - Choose a CIDR range for VPC (default)

11. Subnet03Block - Choose a CIDR range for VPC (default)

12. Choose create on the review page

13. when your stack is created, select it in the console and choose outputs

14. Record the SecurityGroups value that was created, will be needed to create your EKS cluster

- This security group is applied to the cross account ENIs that are created in the subnets that allow the Amazon EKS control plane to communicate with worker nodes

15. Record the VpcID for the subnets that were created (needed to launch worker node group template)

**Installing and Configuring Kubectl For AWS EKS**

- You have multiple options to download and install kubectl for the OS

- The kubectl binary is available in many OS package managers which is much easier than manual download and install process

- Amazon EKS also vends kubectl binaries that you can use, identical to the upstream kubectl binaries with the same version

**To install Aws-iam-authenticator for Amazon EKS**

- Amazon EKS vends the aws-iam-authenticator binaries that can be used or else you need to use "go get" to fetch the binary from the AWS IAM authenticator for the kubernetes project on GitHub for other OS

- Use command to download the binary, subbing the correct URL for the platform. Example for macOS:

  curl -o aws-iam-authenticator https://amazon-eks.s3..../aws-iam-authenticator

Installing Kubectl cmd line interface tool

1. Download the Kubectl binaries
2. change permission:
   chmod +x ./kubectl
3. Copy it in a folder and add it to the environmental path so it is accesible everywhere

4. Check by using
   kubectl version --short --client

Installing the aws-iam-authenticator binary

Same as for the Kubectl

Installing AWS CLI

use pip3 install awscli --upgrade --user

Or..
Downloading

1. Install aws-cli by downloading and unzipping and installing

2. Configure the awscli
   aws configure

   AWS ACCESS KEY ID: [aws access Key of the user that created the cluster]
   AWS SECRET ACCESS KEY: [aws secret access Key of the user that created the cluster]
   Default region name: [region name]
   Default output format: [ json ]

**Creating Amazon EKS cluster in the Console**

- The IAM entity that creates the cluster is added to the Kubernetes RBAC authorization table as the admin

- AWS IAM authenticator uses the AWS SDK for Go to authenticate against the amazon EKS cluste (means the IAM user credentials used should be also in the AWS SDK credential chain when running the kubectl commands)

STEPS to create cluster with console:

1. Open [Amazon EKS console](console.aws.amazon.com/eks/home#/clusters)

2. create cluster

3. Fill the following:

   Cluster name - a unique name

   Kubernetes version - the version for it

   Role ARN the IAM role that is created

   VPC that is created

   Subnets - The subnetIDs from the AWS CloudFormation output generated

   Security groups from the AWS CloudFormation output generated

4. Once clicked create, navigate to the cluster page and choose the name of the newly created cluster to view information

- Dedicated security group is recommended for the cluster control plane

- Error: One of the availability zones in request doesnt have sufficient capacity, retry creating the cluster

**Deleting Amazon EKS Cluster**

Delete the cluster to avoid unnecessary costs

if there are active services in the cluster that are associated with the load balancer then we must delete those services before deleting the cluster so that the load balancers will delete properly

Or else there will be orphaned resources in the VPC that will prevent from being able to delete the VPC

STEPS to delete Amazon EKS cluster

1. List all services running in the cluster using

   kubectl get svc--all-

2. Delete any services that have associated EXTERNAL-IP value using

   kubectl delete svc service-name

3. Delete the worker node AWS CloudFormation stack

   - Open AWS CloudFormation
   - select the worker node stack and then choose actions, delete stack
   - Choose yes,delete

4. Delete the cluster

   - Open Amazon EKS console
   - Select the cluster and choose delete
   - Choose delete

**Launching and configuring your Amazon EKS Worker Nodes**

- Wait for your cluster status to show as active

- Open the AWS CloudFormation console

- Select the region that supports the amazon EKS

- Choose Create Stack

- Specify an Amazon S3 template URL for template

- Paste the URL

  https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-11-07/amazon-eks-nodegroup.yaml

- Fill out following parameters on the specify details page

- On options page, choose to tag your stack resources and choose next

- Review page, review info and acknowledge that the stack might create IAM resources and then choose create

- Stack is finished creating, select it in the console and choose the outputs tab

- Record the NodeInstanceRole for the node group (needed to configure the amazon EKS worker nodes)

**Enabling worker nodes to join your cluster**

- Download, edit and apply the aws authenticator config map

- Open the file and replace the <ARN of instance role (not instance profile)> snippet with the NodeInstanceRole value that is recorded

- Apply the configuration using kubectl apply -f aws-auth-cm.yaml

- Watch and Wait for the status of the node to become ready using kubectl get nodes --watch

**Creating the demo app**

- kubernetes repo has 3 demo apps

For the guestbook app,

- Create the Redis master replication controller using,

  kubectl apply -f <link>

- Create the Redis master service

- Create the Redis Slave Replication controller

- Create the Redis Slave Service

- Create the guestbook replication controller

- Create the guestbook service

- Query the services in the cluster and wait until the external IP column for the guestbook service is populated using

  kubectl get services -o wide

- After it is available. enter the IP with port 3000 to view the guestbook application

- Experiment with the deployed app
